---
title: "Homework 2"
author: Pavithra Srinivasan
output: github_document
date: "October 2, 2023"
---

```{r load_libraries}
library(tidyverse)
library(readxl)
```

### Problem 1

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols = 
  read_csv("./data/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez")) 
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv("./data/snp.csv") |>
  separate(date, into = c("month", "day", "year"), convert = TRUE) |>
  arrange(year, month) |>
  mutate(month = month.name[month]) |>
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("./data/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

### Problem 2

Read in and clean the Mr. Trash Wheel sheet:

```{r}
df_trash_wheel = read_excel("./data/trash_wheel.xlsx") 
  sheet = "Mr. Trash Wheel"
  janitor::clean_names(df_trash_wheel)
  names(df_trash_wheel)
  drop_na(df_trash_wheel) |> 
  mutate(homes_powered = (weight_tons*500)/30,
    trash_wheel = "Trash_1"
  )
```

Read in and clean the Professor Trash Wheel sheet:

```{r}
df_prof_wheel = read_excel("./data/trash_wheel.xlsx") 
  sheet = "Professor Trash Wheel"
  janitor::clean_names(df_prof_wheel)
  names(df_prof_wheel)
  drop_na(df_prof_wheel) |> 
  mutate(homes_powered = (weight_tons*500)/30,
    trash_wheel = "Trash_2"
  )
```

Read in and clean the Gwynnda Trash Wheel sheet: 

```{r}
df_gwynn_wheel = read_excel("./data/trash_wheel.xlsx") 
  sheet = "Gwynnda Trash Wheel"
  janitor::clean_names(df_gwynn_wheel)
  names(df_gwynn_wheel)
  drop_na(df_gwynn_wheel) |> 
  mutate(homes_powered = (weight_tons*500)/30,
    trash_wheel = "Trash_3"
  )
```

Tidying and Combining all 3 datasets into one:

```{r}
df_combined_trash = 
  bind_rows(df_trash_wheel, df_prof_wheel, df_gwynn_wheel)
```

PROBLEM 2 DISCUSSION:

This data shows us a combination of all the trash collected between the 3 datasets. Also tells us how much total weight of trash was collected by Mr. Trash Wheel, Professor Trash Wheel and the Gwynnda Trash Wheel collectively. Additionally, it also shows all the different material that was collected such as polystrene, cigarette butts, glass bottles, plastic bags, wrappers and sport balls. There was a total of `r nrow(df_combined_trash)` observations in the combined data set, with `r ncol(df_combined_trash)` key variables. Other key information gained from this data: 

Total weight collected by Professor Trash wheel = `r sum(df_prof_wheel$weight_tons)`


### Problem 3

READ, TIDY AND COMBINE THE MCI BASELINE AND AMYLOID DATASETS:

```{r}

## Cleaning: deleted the first row, changed the sex and apoe variables into non-numerical and removed NA. 

df_MCI_baseline = 
  read_csv("./data/MCI_baseline.csv", skip = 1) %>% 
  janitor::clean_names() %>% 
  mutate(
    sex = case_match(
      sex, 1 ~ "male", 0 ~ "female"),
    apoe4 = case_match(
      apoe4, 1 ~ "carrier", 0 ~ "non_carrier"),
  )

df_MCI_amyloid = 
  read_csv("./data/mci_amyloid.csv", skip = 1) %>%
  janitor::clean_names() %>% 
  mutate(id = `study_id`) %>% 
  select(-study_id)
  drop_na(df_MCI_amyloid)
```

PROBLEM 3 DISCUSSION QUESTIONS: 

1. Total participants recruited?
`r nrow(df_MCI_baseline)`

2. Of these participants, how many developed MCI?
```{r}
filter(df_MCI_baseline, age_at_onset != ".")

## Of the participants recruited, 97 developed MCI.
```

3. Avg. Baseline age?
```{r}
mean(pull(df_MCI_baseline, current_age))
```

4. What proportion of women are APOE4 carriers?
```{r}
filter(df_MCI_baseline, sex != "male", apoe4 != "non_carrier")

## 63 women are APOE4 carriers.
```
 
5. Comment on the steps on the import process and the features of the Amyloid dataset:

Read in and cleaned the overall data set. Conditionally mutated the "study id" variable to just "id" so it can correspond to the participants of the data set, and also stay consistent with the baseline dataset. Then the "NA" values were dropped to create a cohesive data-frame.


6. Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. 

```{r}
df_only_baseline =
  df_MCI_baseline |>
  anti_join(df_MCI_amyloid, by = "id")

df_only_baseline
## Study participants 14, 49, 92, 179, 268, 304, 389 and 412 are unique to the baseline dataset. 
```
```{r}

df_only_amyloid = 
  df_MCI_amyloid |>
  anti_join(df_MCI_baseline, by = "id")

df_only_amyloid
## Study participants 484-495 are unique to only the amyloid dataset. 
```

7. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset.

```{r}
df_MCI_combined = 
  inner_join(df_MCI_baseline, df_MCI_amyloid, by = "id")

df_MCI_combined

## 475 participants appear in both datasets
```

8. Exporting the result as a csv to your data directory: 
```{r}
write.csv(df_MCI_combined, file = "results/df_MCI_combined.csv")

```



